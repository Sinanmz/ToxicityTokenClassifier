# ToxicityTokenClassifier
This repository contains code for training and deploying two models to classify toxic words within sentences. The first model utilizes an LSTM-CRF architecture, while the second model is a fine-tuned transformer using the Hugging Face library. Both models operate at the token level, providing accurate detection of toxic language.
